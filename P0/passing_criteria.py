"""Provide feedback to student based on evaluation of JavaScript programming quiz."""

import json

# until we check, assume student's submission is incorrect
grade_result['correct'] = False

# don't use, but must set to ' ' to avoid error
grade_result['comment'] = ' '

# use default markdown?
use_default_markdown = True

def parse_swizzled_output(output):
    """Analyzes the swizzled output for passing/failing criteria and other feedback.
        
        Args:
        output (string): Output generated when running swizzled main.
        """
    # keep running total of (passed) criteria
    numberOfCriteria = 0
    numberOfPasses = 0
    passed_criteria = []
    failed_criteria = []
    feedback = []
    # split lines by newline
    lines = output.split('\n')
    # go line-by-line and find formatted tags for criteria
    for line in lines:
        if line.startswith('<PASS::>'):
            numberOfCriteria += 1
            numberOfPasses += 1
            # strip tag and add criteria to array
            passed_criteria.append(line[8:])
        if line.startswith('<FAIL::>'):
            numberOfCriteria += 1
            # strip tag and add criteria to array
            failed_criteria.append(line[8:])
        if line.startswith('<FEEDBACK::>'):
            # strip tag and add feedback to array
            feedback.append(line[12:])
    # return results
    return (numberOfCriteria == numberOfPasses, passed_criteria, failed_criteria, feedback)

def default_markdown_from_criteria(passing_criteria, failing_criteria):
    """Generates default markdown-like string based on passing/failing criteria.

        Args:
        passing_criteria (list): All passing criteria from quiz
        failing_criteria (list): All failing criteria from quiz
        """
    # init markdown-like string
    markdown = ''
    # was there more than 1 criteria?
    if passing_criteria + failing_criteria > 1:
        # add passing criteria to markdown
        if len(passing_criteria) >= 1:
            markdown += '# What Went Well\n\n'
            for criteria in passing_criteria:
                markdown += '<li style="list-style-type: none;">- ' + criteria + '</li>'
            markdown += '\n'
        # add failing criteria to markdown
        if len(failing_criteria) >= 1:
            markdown += '# What Went Wrong\n\n'
            for criteria in failing_criteria:
                markdown += '<li style="list-style-type: none;">- ' + criteria + '</li>'
            markdown += '\n'
    else:
        # if only 1 criteria, add it without headers to markdown
        markdown = passing_criteria[0] if grade_result['correct'] else failing_criteria[0]
    # return markdown-like string
    return markdown

def main():
    """Analyze the output generated by Falcon and set special key/value pairs for feedback."""
    # did the remote execution cause an error?
    if executor_result['stderr'] == '':
        # nope! analyze the output (JSON-like string)
        try:
            # convert JSON-like string into Python dictionary
            results = json.loads(executor_result['stdout'])
            swizzle_out = results['temp/results-out.txt']
        except Exception as e:
            # if there was an error during the conversion, display it
            grade_result['feedback'] = executor_result['stderr']
        else:
            # did the execution of swizzled main produce an error?
            if results['temp/results-err.txt'] == '':
                # nope! we can safely use the output of swizzled main
                (submission_correct, passing_criteria, failing_criteria, feedback) = parse_swizzled_output(swizzle_out)
                # set pass/fail
                grade_result['correct'] = submission_correct
                if use_default_markdown == True:
                    # use default markdown for criteria/feedback
                    markdown_feedback = default_markdown_from_criteria(passing_criteria, failing_criteria)
                    total_criteria = len(failing_criteria) + len(passing_criteria)
                    all_feedback = markdown_feedback + '# Feedback\n\n'
                    if len(failing_criteria) == 0:
                        all_feedback += 'Your answer passed all our tests! Awesome job!'
                    elif len(passing_criteria) >= total_criteria / 2:
                        all_feedback += 'Not everything is correct yet, but you\'re close!'
                    else:
                        all_feedback += 'There\'s work left to do. Try tackling one problem at a time.'
                    grade_result['feedback'] = all_feedback
                    # grade_result['comment'] = results['temp/student-out.txt']
                else:
                    # show raw response from REX execution
                    grade_result['feedback'] = str(results)
            else:
                # swizzled main generated some an error, so display it!
                grade_result['feedback'] = 'An error occurred while testing your code.\n\nCheck to ensure these items are true:\n\n- clicking **TEST RUN** doesn\'t produce any issues\n- you\'ve followed all instructions\n- you\'ve used the correct names\n\nIf you make all these checks, but it still doesn\'t fix the error, then please contact us at *support@udacity.com* and provide a link to the quiz and a copy of your code.\n\nNOTE: If you cannot find the instructions, click **RESET QUIZ** to reset the quiz to its original state.'
    else:
        # there was an error with overall execution, so display it!
        grade_result['comment'] = executor_result['stderr']

main()